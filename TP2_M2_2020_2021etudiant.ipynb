{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_M2_2020_2021etudiant.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mordor-ai/M2-MIASHS-DIVERS/blob/main/TP2_M2_2020_2021etudiant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWG9kw3t0ZsQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TGeMuN4Kye3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00ec4a0-f10e-4d72-98cc-970c31aed274"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "class_names = ['Avion', 'auto', 'oiseau', 'chat', 'biche',\n",
        "               'chien', 'grenouille', 'cheval', 'bateau', 'camion']\n",
        "               \n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2WlyMz_PWc6"
      },
      "source": [
        "Pour comprendre comment ajouter des régularisations à vos réseaux allez voir les pages : \n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "Implémenter le réseau suivant (la fonction d'activation est une ReLU) : \n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "\n",
        "conv2d_44 (Conv2D)           (None, 30, 30, 64)        1792      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_20 (MaxPooling (None, 15, 15, 64)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_45 (Conv2D)           (None, 13, 13, 128)       73856     \n",
        "_________________________________________________________________\n",
        "conv2d_46 (Conv2D)           (None, 11, 11, 128)       147584    \n",
        "_________________________________________________________________\n",
        "max_pooling2d_21 (MaxPooling (None, 5, 5, 128)         0         \n",
        "_________________________________________________________________\n",
        "conv2d_47 (Conv2D)           (None, 3, 3, 128)         147584    \n",
        "_________________________________________________________________\n",
        "conv2d_48 (Conv2D)           (None, 1, 1, 128)         147584    \n",
        "_________________________________________________________________\n",
        "flatten_10 (Flatten)         (None, 128)               0         \n",
        "_________________________________________________________________\n",
        "dense_20 (Dense)             (None, 64)                8256      \n",
        "_________________________________________________________________\n",
        "dense_21 (Dense)             (None, 10)                650       \n",
        "```\n",
        "\n",
        "Entraînez le en utilisant les paramètres par défaut de l'optimiseur Adam pendant 20 époques. \n",
        "\n",
        "**Notez les performances et les valeurs finales de la loss de train et de la loss de test**\n",
        "\n",
        "Modifiez votre réseau pour effectuer les tests suivants : \n",
        "\n",
        "\n",
        "*   Une régularisation L1 avec un poids de 0.00001 sur chaque couche\n",
        "*   Une régularisation L2 avec un poids de 0.001 sur chaque couche\n",
        "*   Une régularisation L2 avec un poids de 0.001 sur chaque couche sauf les deux premières\n",
        "*   Une régularisation L2 avec un poids de 0.01 sur chaque couche\n",
        "\n",
        "**Que pouvez vous conclure des résultats obtenus ?**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygHU7o9MKyic"
      },
      "source": [
        "def createModel(gammaL1, gammaL2, first = False):\n",
        "  randomName = \"conv\"+str(random.random())\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), \n",
        "                          bias_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1) if first else None, #64\n",
        "                          kernel_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1) if first else None))#3x64x3x3\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', \n",
        "                          bias_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1) if first else None, \n",
        "                          kernel_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1) if first else None))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', \n",
        "                          kernel_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1), \n",
        "                          bias_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', \n",
        "                          kernel_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1), \n",
        "                          bias_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1)))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', \n",
        "                            activity_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1), name=randomName, \n",
        "                            bias_regularizer=tf.keras.regularizers.L1L2(l2=gammaL2, l1=gammaL1)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10))\n",
        "\n",
        "  model_tmp = tf.keras.Model(inputs=model.input, outputs=model.get_layer(randomName).output)\n",
        "\n",
        "  #ICI \n",
        "  return model,model_tmp\n",
        "\n",
        "\n",
        "def draw_projection(model_tmp, with_test, with_train, maximum=1000):\n",
        "  data  = []\n",
        "  labels = []\n",
        "  marker = []\n",
        "  if with_test:\n",
        "    for i in range(0, test_images.shape[0], 100):\n",
        "      data += list(model_tmp.predict(test_images[i:i+100]).reshape(100, -1))\n",
        "      labels += list(test_labels[i:i+100])\n",
        "    marker +=[1] * test_labels.shape[0]\n",
        "\n",
        "\n",
        "  if with_train:\n",
        "    for i in range(0, train_images.shape[0], 100):\n",
        "      data += list(model_tmp.predict(train_images[i:i+100]).reshape(100, -1))\n",
        "      labels += list(train_labels[i:i+100])\n",
        "    marker +=[0] * train_labels.shape[0]\n",
        "\n",
        "  data = np.array(data)\n",
        "  labels=np.array(labels)\n",
        "  marker=np.array(marker)\n",
        "\n",
        "  index = np.arange(0, int(labels.shape[0]))\n",
        "  np.random.shuffle(index)\n",
        "  \n",
        "  data   = data[index[:maximum]]\n",
        "  labels = labels[index[:maximum]]\n",
        "  marker = marker[index[:maximum]]\n",
        "\n",
        "\n",
        "  data_tsne = TSNE(n_components=2).fit_transform(data)\n",
        "  data_pca = PCA(n_components=2).fit_transform(data)\n",
        "  if with_train:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(data_pca[marker==0, 0], data_pca[marker==0, 1], c=labels[marker==0], marker=\"x\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(data_tsne[marker==0, 0], data_tsne[marker==0, 1], c=labels[marker==0], marker=\"x\")\n",
        "    plt.colorbar()\n",
        "  if with_test:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(data_pca[marker==1, 0], data_pca[marker==1, 1], c=labels[marker==1], marker=\"o\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(data_tsne[marker==1, 0], data_tsne[marker==1, 1], c=labels[marker==1], marker=\"o\")\n",
        "    plt.colorbar()\n",
        "\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(20, 10)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ykrovKdqqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORt9UYRTKylQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "7170e8b1-c1f8-4046-a865-ec64365b10c2"
      },
      "source": [
        "\n",
        "\n",
        "params=[[0,0,False],[0.00001,0,True],[0,0.001,True],[0,0.001,False],[0,0.01,True]]\n",
        "for param in params:\n",
        "  model, model_tmp = createModel(param[0], param[1], param[2]) # on enleve le '_'\n",
        "  print(\"L1 : \", param[0],\"  L2 : \", param[1],\" First : \", param[2])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  model.fit(train_images, train_labels, epochs=19, \n",
        "                      validation_data=(test_images, test_labels), verbose=0)\n",
        "  model.fit(train_images, train_labels, epochs=1, \n",
        "                      validation_data=(test_images, test_labels), verbose=1)\n",
        "\n",
        "  print (\"TEST\")\n",
        "  draw_projection(model_tmp, with_test=True, with_train=False, maximum=7500)\n",
        "  print (\"TRAIN\")\n",
        "  draw_projection(model_tmp, with_test=False, with_train=True, maximum=7500)\n",
        "  print (\"TRAIN+TEST\")\n",
        "  draw_projection(model_tmp, with_test=True, with_train=True, maximum=10000)\n",
        "\n",
        "  print (\"-\"*35)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1 :  0   L2 :  0  First :  False\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1731 - accuracy: 0.9409 - val_loss: 1.4125 - val_accuracy: 0.7217\n",
            "-----------------------------------\n",
            "L1 :  1e-05   L2 :  0  First :  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e63fc6673d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   model.fit(train_images, train_labels, epochs=19, \n\u001b[0;32m---> 14\u001b[0;31m                       validation_data=(test_images, test_labels), verbose=0)\n\u001b[0m\u001b[1;32m     15\u001b[0m   model.fit(train_images, train_labels, epochs=1, \n\u001b[1;32m     16\u001b[0m                       validation_data=(test_images, test_labels), verbose=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNG-zwORJ_l"
      },
      "source": [
        "# Projection 2D\n",
        "\n",
        "Pour chaque réseau précédemment entrainé afficher la représentation t-SNE et la PCA des données en considérant d'abord seulement la base d'entraînement puis seulement la base de test et enfin les bases d'entraînnement et de test ensembles. Vous utiliserez les cartes de caractéristiques de la 5ème convolution. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcRwhBEcKyu-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT0Y3I0A2lYG"
      },
      "source": [
        "# Pour allez plus loin\n",
        "Ajoutez une régularisation, avec un poids que vous estimerez par l'expérimentation, sur la sortie de la 5ème convolution (et non sur les valeurs des poids). Après avoir effectué un entraînement, affichez la projection 2D de la 5ème convolution.\n",
        "\n",
        "\n",
        "\n",
        "Répétez l'opération en choisissant une régularisation de type KL divergence avec un paramètre de sparcité égale à 0.001. **Vous devez implémenter cette régularisation et modifier le réseau pour que celle-ci fonctionne.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5nZVh3dRsHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcHJLI3sRsbq"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# La classification, le deep learning et la réalité\n",
        "\n",
        "Pour tous les TP qui suivent nous allons nous intéresser à un vrai problème de classification. Nous allons chercher à détecter les visages et à discriminer les personnes ayant un masque des autres. \n",
        "\n",
        "Pour cela nous allons utiliser trois bases trouvées sur internet. Chaque base comporte son format d'annotation et ses règles de labellisation. De plus les images étant issues du monde réel elles seront de différentes tailles et résolutions. \n",
        "\n",
        "1.   Téléchargez les données en utilisant le lien suivant : https://we.tl/t-UfSJCPGKZ3\n",
        "2.   Complétez les classes 'Objet' et 'DataGenerator' afin que la classe 'DataGenerator' retourne des images avec la vérité terrain associée (en terme de segmentation pixel)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsATKZojdfvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1046355b-76d3-4eb8-be38-58771fe599e3"
      },
      "source": [
        "!wget --user-agent Mozilla/4.0 'https://download.wetransfer.com//eu2/5a5d8f7599ac518caa5b1652e4c658a920201111135405/e0ad236d54b2ffb0c92751a9e46f0dcc6b6faff1/out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDUxMzUwMjcsInVuaXF1ZSI6IjVhNWQ4Zjc1OTlhYzUxOGNhYTViMTY1MmU0YzY1OGE5MjAyMDExMTExMzU0MDUiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFja2VuZC5zZXJ2aWNlLmV1LXdlc3QtMS53dDo5MjkyL3dheWJpbGwvdjEvc2Fya2FyL2ViOGI2NGEzNTQ1ODVmMDVkN2E5MGNlNzFiYmVkNzEyYzY5YmU0Zjc5MmJlNTgzZTVmNGM1MTkyZGRiZjBiYjc0ZmNkZThhZGQzMGY5MTY2ZDlkMTBmIiwiZmluZ2VycHJpbnQiOiJlMGFkMjM2ZDU0YjJmZmIwYzkyNzUxYTllNDZmMGRjYzZiNmZhZmYxIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL3Byb2R1Y3Rpb24uZnJvbnRlbmQuc2VydmljZS5ldS13ZXN0LTEud3Q6MzAwMC93ZWJob29rcy9iYWNrZW5kXCJ9LFwiZm9ybVwiOntcInRyYW5zZmVyX2lkXCI6XCI1YTVkOGY3NTk5YWM1MThjYWE1YjE2NTJlNGM2NThhOTIwMjAxMTExMTM1NDA1XCIsXCJkb3dubG9hZF9pZFwiOjEwNzEyMjE2NzI2fX0ifQ.qeU1IgXPulzP02kdsTE1DLsYtN5p45X3vPNxLMYv4dE' -O dest_file_name\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-11 22:40:52--  https://download.wetransfer.com//eu2/5a5d8f7599ac518caa5b1652e4c658a920201111135405/e0ad236d54b2ffb0c92751a9e46f0dcc6b6faff1/out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDUxMzUwMjcsInVuaXF1ZSI6IjVhNWQ4Zjc1OTlhYzUxOGNhYTViMTY1MmU0YzY1OGE5MjAyMDExMTExMzU0MDUiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFja2VuZC5zZXJ2aWNlLmV1LXdlc3QtMS53dDo5MjkyL3dheWJpbGwvdjEvc2Fya2FyL2ViOGI2NGEzNTQ1ODVmMDVkN2E5MGNlNzFiYmVkNzEyYzY5YmU0Zjc5MmJlNTgzZTVmNGM1MTkyZGRiZjBiYjc0ZmNkZThhZGQzMGY5MTY2ZDlkMTBmIiwiZmluZ2VycHJpbnQiOiJlMGFkMjM2ZDU0YjJmZmIwYzkyNzUxYTllNDZmMGRjYzZiNmZhZmYxIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL3Byb2R1Y3Rpb24uZnJvbnRlbmQuc2VydmljZS5ldS13ZXN0LTEud3Q6MzAwMC93ZWJob29rcy9iYWNrZW5kXCJ9LFwiZm9ybVwiOntcInRyYW5zZmVyX2lkXCI6XCI1YTVkOGY3NTk5YWM1MThjYWE1YjE2NTJlNGM2NThhOTIwMjAxMTExMTM1NDA1XCIsXCJkb3dubG9hZF9pZFwiOjEwNzEyMjE2NzI2fX0ifQ.qeU1IgXPulzP02kdsTE1DLsYtN5p45X3vPNxLMYv4dE\n",
            "Resolving download.wetransfer.com (download.wetransfer.com)... 13.249.43.75, 13.249.43.54, 13.249.43.76, ...\n",
            "Connecting to download.wetransfer.com (download.wetransfer.com)|13.249.43.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073397798 (1024M) [binary/octet-stream]\n",
            "Saving to: ‘dest_file_name’\n",
            "\n",
            "dest_file_name       61%[===========>        ] 634.14M  1.69MB/s    eta 2m 54s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVBDJaAPCtVs",
        "outputId": "da5219b8-a30b-4cf8-9ef7-1fbca98af009"
      },
      "source": [
        "!wget --user-agent Mozilla/4.0 'https://download.wetransfer.com//eu2/9b751cb3099a84b606b98b9426215dcd20201217092809/e0ad236d54b2ffb0c92751a9e46f0dcc6b6faff1/out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDgxOTgxNTcsInVuaXF1ZSI6IjliNzUxY2IzMDk5YTg0YjYwNmI5OGI5NDI2MjE1ZGNkMjAyMDEyMTcwOTI4MDkiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFja2VuZC5zZXJ2aWNlLmV1LXdlc3QtMS53dDo5MjkyL3dheWJpbGwvdjEvc2Fya2FyLzRlZDU4ZmI2NmJlY2Y4Yzg2ZjFkNDNiYzdmN2ZkZDRmMWM2MWE0ZjNhNzczMTk4MGY1ZmZjYWU2YTIwYTg0ZDdmNGE0Mzc4ODZmMjRmMWNjM2MzOWQ5IiwiZmluZ2VycHJpbnQiOiJlMGFkMjM2ZDU0YjJmZmIwYzkyNzUxYTllNDZmMGRjYzZiNmZhZmYxIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL3Byb2R1Y3Rpb24uZnJvbnRlbmQuc2VydmljZS5ldS13ZXN0LTEud3Q6MzAwMC93ZWJob29rcy9iYWNrZW5kXCJ9LFwiZm9ybVwiOntcInRyYW5zZmVyX2lkXCI6XCI5Yjc1MWNiMzA5OWE4NGI2MDZiOThiOTQyNjIxNWRjZDIwMjAxMjE3MDkyODA5XCIsXCJkb3dubG9hZF9pZFwiOjExMDE5MTkwMTczfX0ifQ.GJ-39bdctQN51UKzcZ0moUG-3c-ZEmxhsyAKDnS7ZnA'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The name is too long, 834 chars total.\n",
            "Trying to shorten...\n",
            "New name is out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDgxOTgxNTcsInVuaXF1ZSI6IjliNzUxY2IzMDk5YTg0YjYwNmI5OGI5NDI2MjE1ZGNkMjAyMDEyMTcwOTI4MDkiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFj.\n",
            "--2020-12-17 09:32:51--  https://download.wetransfer.com//eu2/9b751cb3099a84b606b98b9426215dcd20201217092809/e0ad236d54b2ffb0c92751a9e46f0dcc6b6faff1/out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDgxOTgxNTcsInVuaXF1ZSI6IjliNzUxY2IzMDk5YTg0YjYwNmI5OGI5NDI2MjE1ZGNkMjAyMDEyMTcwOTI4MDkiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFja2VuZC5zZXJ2aWNlLmV1LXdlc3QtMS53dDo5MjkyL3dheWJpbGwvdjEvc2Fya2FyLzRlZDU4ZmI2NmJlY2Y4Yzg2ZjFkNDNiYzdmN2ZkZDRmMWM2MWE0ZjNhNzczMTk4MGY1ZmZjYWU2YTIwYTg0ZDdmNGE0Mzc4ODZmMjRmMWNjM2MzOWQ5IiwiZmluZ2VycHJpbnQiOiJlMGFkMjM2ZDU0YjJmZmIwYzkyNzUxYTllNDZmMGRjYzZiNmZhZmYxIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL3Byb2R1Y3Rpb24uZnJvbnRlbmQuc2VydmljZS5ldS13ZXN0LTEud3Q6MzAwMC93ZWJob29rcy9iYWNrZW5kXCJ9LFwiZm9ybVwiOntcInRyYW5zZmVyX2lkXCI6XCI5Yjc1MWNiMzA5OWE4NGI2MDZiOThiOTQyNjIxNWRjZDIwMjAxMjE3MDkyODA5XCIsXCJkb3dubG9hZF9pZFwiOjExMDE5MTkwMTczfX0ifQ.GJ-39bdctQN51UKzcZ0moUG-3c-ZEmxhsyAKDnS7ZnA\n",
            "Resolving download.wetransfer.com (download.wetransfer.com)... 54.192.86.43, 54.192.86.16, 54.192.86.124, ...\n",
            "Connecting to download.wetransfer.com (download.wetransfer.com)|54.192.86.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073397798 (1024M) [binary/octet-stream]\n",
            "Saving to: ‘out_toto.tar.gz?cf=y&token=eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDgxOTgxNTcsInVuaXF1ZSI6IjliNzUxY2IzMDk5YTg0YjYwNmI5OGI5NDI2MjE1ZGNkMjAyMDEyMTcwOTI4MDkiLCJmaWxlbmFtZSI6Im91dF90b3RvLnRhci5neiIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFj’\n",
            "\n",
            "to.tar.gz?cf=y&toke   1%[                    ]  16.35M  4.00MB/s    eta 4m 49s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvGe6w9CKyz6"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "FOLDER_DATA=\"./\"\n",
        "NCROSS = 5\n",
        "CROSS  = 0\n",
        "batch_size = 32\n",
        "TAILLE_MAX=512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xljs_88K30Wl"
      },
      "source": [
        "class Objet:\n",
        "    def __init__(self, xml_part):\n",
        "        self.name = str(xml_part.find('name').text)\n",
        "        self.xmin = int(xml_part.find('bndbox').find('xmin').text)\n",
        "        self.xmax = int(xml_part.find('bndbox').find('xmax').text)\n",
        "        self.ymin = int(xml_part.find('bndbox').find('ymin').text)\n",
        "        self.ymax = int(xml_part.find('bndbox').find('ymax').text)\n",
        "    def __str__(self):\n",
        "        return self.name+\" \"+str(self.xmin)+\" \"+str(self.xmax)+\" \"+str(self.ymin)+\" \"+str(self.ymax)+\" \"+str(self.label)\n",
        "\n",
        "\n",
        "class ReadXML:\n",
        "    def __init__(self, ch):\n",
        "        tree = ET.parse(ch)\n",
        "        self.root = tree.getroot()\n",
        "        self.filename=  self.root.find('filename').text\n",
        "        if \"annotations\" in ch:\n",
        "            self.image  = imageio.imread(FOLDER_DATA+'/images/'+self.filename)[:,:,:3]/255.0\n",
        "        elif \"medical-masks-dataset\" in ch:\n",
        "            self.image  = imageio.imread(FOLDER_DATA+'/medical-masks-dataset/images/'+self.filename)[:,:,:3]/255.0\n",
        "\n",
        "        # On souhaite avoir une largeur/hauteur de taille maximale TAILLE_MAX ET chaque dimension doit-être un multiple de 32\n",
        "        # self.image : L'image en entrée\n",
        "        # self.image_zone : la vérité terrain (W, H, Nb Labels)\n",
        "        # CODE A FAIRE \n",
        "\n",
        "\n",
        "        self.image_zone = np.zeros((self.image.shape[0], self.image.shape[1], 3), dtype=np.int32)\n",
        "        self.image_zone[:,:, 0]=1\n",
        "        \n",
        "        for i, ob in enumerate(self.root.findall('object')):\n",
        "            tmp = Objet(ob)\n",
        "            label=-1\n",
        "            if \"annotations\" in ch:\n",
        "                if tmp.name==\"with_mask\":            \n",
        "                    label=2\n",
        "                elif tmp.name==\"mask_weared_incorrect\":\n",
        "                    label=2\n",
        "                elif tmp.name==\"without_mask\":\n",
        "                    label=1\n",
        "                else:\n",
        "                    print(\"BUG\")\n",
        "            else:\n",
        "                if tmp.name==\"mask\":            \n",
        "                    label=2\n",
        "                elif tmp.name==\"poor\":\n",
        "                    label=2\n",
        "                elif tmp.name==\"none\":\n",
        "                    label=1\n",
        "                else:\n",
        "                    print(\"BUG\")\n",
        "\n",
        "\n",
        "            # On complète le code en mettant à jour le tableau 'self.image_zone'\n",
        "            # CODE A FAIRE \n",
        "\n",
        "          \n",
        "\n",
        "                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXHTneL630Yv"
      },
      "source": [
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data_link, batch_size=32,  shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.data={}\n",
        "        #Compléter l'initialisation du générateur\n",
        "        # CODE A FAIRE                               \n",
        "        self.indices = list(self.data.keys())\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.indices) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        keys = [self.indices[k] for k in index]\n",
        "        return self.__get_data(keys)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index = np.arange(len(self.indices))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.index)\n",
        "\n",
        "            \n",
        "    def __get_data(self, keys):        \n",
        "        pass\n",
        "        #Compléter la méthode qui doit retourner : l'image (Nb Batch, H, W, 3) ,  la vérité terrain (Nb Batch, H, W, 3)\n",
        "        # CODE A FAIRE \n",
        "                \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aye8Z6nZ30bR"
      },
      "source": [
        "\n",
        "all_xml = glob.glob(FOLDER_DATA+'/medical-masks-dataset/labels/*.xml')+glob.glob(+FOLDER_DATA\"/annotations/*.xml\")\n",
        "random.seed(42)\n",
        "random.shuffle(all_xml)\n",
        "\n",
        "\n",
        "sp = np.array_split(all_xml, NCROSS)\n",
        "test_xml_imggb  = sp[CROSS]\n",
        "train_xml_imggb = np.concatenate([x for i,x in enumerate(sp) if i!=CROSS], axis=0) \n",
        "train_xml_imggb = train_xml_imggb\n",
        "test_xml_imggb  = test_xml_imggb\n",
        "\n",
        "print (\"TAILLE TEST \",len(test_xml_imggb) )\n",
        "print (\"TAILLE TRAIN \",len(train_xml_imggb) )\n",
        "train = DataGenerator(data_link=train_xml_imggb, batch_size=batch_size,  shuffle=True)\n",
        "val   = DataGenerator(data_link=test_xml_imggb, batch_size=batch_size,  shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}